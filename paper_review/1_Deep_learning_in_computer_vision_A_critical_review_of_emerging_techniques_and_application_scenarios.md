컴퓨터 비전 1주차 논문리뷰

2021312088 백인진

본 논문은 Deep Learning 기술을 기반으로 Computer Vision 분야의 최근까지
다뤄온 문제 상황과 그에 대한 기술적 해결 방법에 대해 이야기하고 있다.
2012년부터 제안된 8가지의 기술과 4가지 분야의 문제 상황을 제시하며
Computer Vision 분야의 발자취를 기록한다.

논문에 따르면 CV 분야의 주된 기술은 CNN을 기반하고 있다. 먼저 2012년
제안된 AlexNet은 5개의 컨볼루션 레이어와 3개의 fully connected 레이어로
구성되며 활성화 함수로는 Relu를 사용한다. 이는 Caffenet과 pooling,
normalization 순서가 반대된다는 특징을 갖는다. VGGNet의 경우, 성능
개선을 기대하며 뉴럴 네트워크의 깊이를 늘리며 비교적 작은 크기의
컨볼루션 레이어의 수를 늘렸다. 이 과정에서 매개변수의 수가 늘어나 비교적
우수한 성능을 보인다. GoogleNet & Inception은 2014년 제안된 방법으로
NIN방식을 소개하며 등장한다. NIN방식은 컨볼루션 필터를 비선형 함수로
대체한 뒤 근사하며, fully connected 레이어 대신 global average pooling을
사용해 적은 수의 매개변수를 활용하도록 한다. Inception의 경우, 많은 수의
매개변수와 컴퓨팅 자원 요구 증대 라는 단점을 해결하기 위해 등장한
방식으로 컴퓨팅 자원의 사용 정도를 유지한 채 네트워크의 깊이와 너비를
늘리는 방식으로 고안되었다. 이후 큰 사이즈의 필터가 불균형을 초래한다고
판단하여 큰 사이즈의 필터를 작은 사이즈의 필터 2개로 대체하는 방식 또한
등장하였고 batch normalization의 사용, inception 모듈을 분리된 컨볼루션
모듈로 대체하는 등 다양한 발전된 모델이 등장하였다. 다음으로 ResNet의
경우, 매개변수가 아닌 입력에 대한 residual을 학습하도록 하는
알고리즘이다. 이는 매개변수를 줄이는 동시에 feature 전파를 강화하고,
재사용을 장려하며 vanishing gradient problem을 해결하는 데에 효과적이다.
DenseMet은 컨볼루션 네트워크가 보다 정확하고 빠르다는 관찰 하에 모든
레이어를 직접 서로 연결하도록 구성되었다. 이를 통해 ResNet이 얻는 장점과
동일한 장점을 얻는다. MobileNet의 경우, 속도와 정확성을 절충하는 모델로
다양한 버전이 제시되었다. 초기 버전은 매개변수의 수를 줄여 속도를
개선하였고 이후 ReLU 대신 선형 함수를 활용해 비선형 계층으로 인해 정보를
잃는 일이 없도록 하였다. 이후 NAS, NetAdapt 알고리즘을 적용하여 성능을
향상시켰고 시간 또한 단축한다. 다음으로 EfficientNet은 네트워크의 깊이,
너비, 해상도의 균형을 유지함으로써 성능을 향상시키고자 했다. 마지막으로
RegNet은 manual design과 NAS의 장점을 결합한 구조이다. GPU 환경에서
EfficienNet 모델에 비해 최대 5배 빠른 속도를 보이는 동시에 뛰어난 성능을
보인다. 더불어 입력 이미지에서 공간, 순서 정보를 포착하기 위해
ConvLSTM을 제시하여 인코더, 디코더 네트워크를 사용하기도 한다.

이후 4가지 문제 상황에 대해서는 recognition, visual tracking, semantic
segmentation, image restoration의 분류로 나누어 설명한다.
Recognition에는 이미지 분류와 개체 검출이 있는데 개체 검출에는 1단계로
끝나는 YOLO, SSD, RetinaNet이 있으며 2단계 검출 방식은 R-CNN 기반의
다양한 방식이 존재한다. 1단계 검출 방식은 속도면에서 우수하고 2단계 검출
방식은 정확도면에서 우수하다. 2단계 검출 방식은 물체가 있을법한 bounding
box를 찾아내고 그 안의 물체가 무엇인지 classification하는 방식으로
이뤄진다. Visual tracking의 경우, 학자에 따라 Multi-cue 추적, feature
표현 학습의 문제 등 그 정의를 다양하게 한다. 이에 대해 성능을 높이고자
weak tracker를 여러개 사용하거나 하는 등 다양한 방식을 활용한다.
2018년에는 현재의 tracker가 positive sample의 경우 상당수 overlap되어
있고 positive, negative 데이터의 불균형이 존재한다는 단점을 지적하며,
이를 해결하기 위해 네트워크를 활용하여 마스크를 랜덤하게 생성하고
negative 데이터의 영향을 줄이고자 cost sensitive한 손실 함수를 활용한다.
이를 통해 성능 개선을 얻어낸다. 다음으로 Semantic segmentation은 분류와
세분화의 작업으로 나누어 각 작업에 대해 별도의 모델을 훈련하는 방식에서
개선되었다. 2016년에는 SharpMask 방법을 통해 하향식 개선을 활용하여
feedforward 네트워크를 보강하고 DeepMask 네트워크와 결합하였다. 더불어
이 방법은 영상 분할 연구와 함께 활용되어 의료 영역에서도 사용되고 잇다.
또한 데이터 증강을 사용하여 제한된 훈련 데이터셋으로 결과의 정확성을
높였다. 마지막으로 Image restoration는 저해상도, 고해상도 이미지 간의
매핑을 학습할 수 있는 방법이다. 첫 레이어는 저해상도 이미지에서 특징을
추출하고 두번째 레이어는 해당 feature map에서 고해상도 feature map으로
매핑한다. 마지막 레이어는 prediction을 결합하여 고해상도 이미지를
제작한다. 이러한 구조는 가볍고 빠른 속도를 보인다. 해당 분야도 다양한
방법이 고안되었는데, 손상된 이미지 만으로 개선된 이미지로 복구하는
방법이 제안되었다.

이러한 방향성 속에서 최근 연구 동향은 아래와 같다. 먼저 SNN, RNN, GAN 등
다양한 네트워크의 유형이 등장하여 반지도학습으로 학습의 방향이
변화하였다. 또한 Computer Vision 기술이 발전함에 따라 3D semantic
segmentation, face detection 등 다양한 응용 프로그램이 등장하였고
이미지와 자연어를 결합한 챗봇의 등장 등 다른 머신 러닝 도메인과
융합하기도 한다. 기술적으로는 모델 시각화, 해석 가능성에 중점을 두고
블랙박스 모형이 아닌 설명 가능한 모형을 구현하기 위한 연구가 진행되고
있다. 또한 모델의 확장성을 넓히고자 모델을 경량화하려는 다양한 시도들이
보인다.
