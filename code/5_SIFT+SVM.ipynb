{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "torchvision.datasets.CIFAR10(root='../data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic gto make matplotlib figures appear inline\n",
    "# in the notebook rather than in a new window\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import torchvision\n",
    "import _pickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for b in range(1, 6):\n",
    "    filename = os.path.join(data_dir, \"data_batch_%d\" % (b,))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        datadict = pickle.load(f, encoding=\"latin1\")\n",
    "        X = datadict[\"data\"]\n",
    "        Y = datadict[\"labels\"]\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)\n",
    "\n",
    "X_train = np.concatenate(xs)\n",
    "y_train = np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30720000\n",
      "30720000\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(data_dir, \"test_batch\")\n",
    "with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f, encoding=\"latin1\")\n",
    "    X = datadict['data']\n",
    "    print(X.size)\n",
    "    Y = datadict['labels']\n",
    "    X_test = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    y_test = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(random_state = 42)\n",
    "sift = cv.SIFT_create()\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_svm_train(x, y, sift, kmeans, classifier):\n",
    "    des_list = []\n",
    "    for img in x:\n",
    "        img = cv.normalize(img, None, 0, 255, cv.NORM_MINMAX).astype('uint8')\n",
    "        kps, des = sift.detectAndCompute(img, None)\n",
    "        des_list.append(des)\n",
    "    des = np.vstack([descriptors for descriptors in des_list if descriptors is not None])\n",
    "    kmeans.fit(des)\n",
    "\n",
    "    features = np.array([des_to_features(des, sift, kmeans, classifier) for des in des_list])\n",
    "    classifier.fit(features, y)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def des_to_features(des, sift, kmeans, classifier):\n",
    "    if des is not None:\n",
    "        labels = kmeans.predict(des)\n",
    "        features = np.bincount(labels, minlength=kmeans.n_clusters).astype(float)\n",
    "        features /= features.sum()  # L1 normalization\n",
    "    else:\n",
    "        features = np.zeros(kmeans.n_clusters)\n",
    "    return features\n",
    "\n",
    "def predict(x, sift, kmeans, classifier):\n",
    "    des_list = []\n",
    "    for img in x:\n",
    "        img = cv.normalize(img, None, 0, 255, cv.NORM_MINMAX).astype('uint8')\n",
    "        kps, des = sift.detectAndCompute(img, None)\n",
    "        des_list.append(des)\n",
    "    features = np.array([des_to_features(des, sift, kmeans, classifier) for des in des_list])\n",
    "    return classifier.predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000.0\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size / 32 / 32 / 3)\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sift_svm_train(X_train, y_train, sift, kmeans, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, sift, kmeans, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.size)\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.2943\n"
     ]
    }
   ],
   "source": [
    "print('accuracy :', (y_test == y_pred).sum() / y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
