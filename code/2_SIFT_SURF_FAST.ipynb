{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"컴퓨터비전_2주차_백인진.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5XekjIkKB2A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641302469386,"user_tz":-540,"elapsed":23928,"user":{"displayName":"백인진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16419007318722218276"}},"outputId":"50515717-8152-4d04-f16c-8c34ef564f89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Found existing installation: opencv-contrib-python 3.4.2.17\n","Uninstalling opencv-contrib-python-3.4.2.17:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_contrib_python-3.4.2.17.dist-info/*\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-contrib-python-3.4.2.17\n","Found existing installation: opencv-python 3.4.2.17\n","Uninstalling opencv-python-3.4.2.17:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/opencv_python-3.4.2.17.dist-info/*\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-3.4.2.17\n","Collecting opencv-python==3.4.2.17\n","  Using cached opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0 MB)\n","Collecting opencv-contrib-python==3.4.2.17\n","  Using cached opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n","Installing collected packages: opencv-python, opencv-contrib-python\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed opencv-contrib-python-3.4.2.17 opencv-python-3.4.2.17\n"]}],"source":["!pip install numpy\n","!pip install matplotlib\n","# !pip install opencv-python\n","\n","!pip uninstall opencv-contrib-python\n","!pip uninstall opencv-python \n","\n","!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17\n","# !pip install opencv-python==3.3.0.10 opencv-contrib-python==3.3.0.10"]},{"cell_type":"code","source":["import cv2 as cv\n","print(cv.__version__)\n","import sys\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","from matplotlib import pyplot as plt"],"metadata":{"id":"ruW8GuUZKDBf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641302488345,"user_tz":-540,"elapsed":328,"user":{"displayName":"백인진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16419007318722218276"}},"outputId":"8199fa25-8682-44b2-831a-fd8bfdc3cc27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.4.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/MyDrive/computer_vision/data')"],"metadata":{"id":"ADKH0jn5KDED","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641302492190,"user_tz":-540,"elapsed":2304,"user":{"displayName":"백인진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16419007318722218276"}},"outputId":"11d64423-60c8-49a9-9be2-3c6eed32e4db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"IgC3uc9qKDGX","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1641302407301,"user_tz":-540,"elapsed":9889,"user":{"displayName":"백인진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16419007318722218276"}},"outputId":"e1a214cb-30e6-403f-9026-5fb968b398b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\n","\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\n","Collecting opencv-python==3.4.2.17\n","  Using cached opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0 MB)\n","Collecting opencv-contrib-python==3.4.2.17\n","  Using cached opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n","Installing collected packages: opencv-python, opencv-contrib-python\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed opencv-contrib-python-3.4.2.17 opencv-python-3.4.2.17\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"id":"ijY_BXTSKDIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"OmQr9wqUKDK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"wg2BpF0yKDNm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SIFT"],"metadata":{"id":"yMlALKhTKDcJ"}},{"cell_type":"code","source":["# Introduction to SIFT (Scale-Invariant Feature Transform)\n","\n","# harris 모서리는 회전에 불변하나 규모에는 변함 ; 규모 공간 극한 탐지, 키포인트 localization, orientation 지정, 키포인트 descriptor, 키포인트 matching\n","\n","\n","img = cv.imread('home.jpg')\n","gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n","sift = cv.SIFT_create()\n","kp = sift.detect(gray,None)\n","img=cv.drawKeypoints(gray,kp,img)\n","cv2_imshow(img)\n","cv.imwrite('sift_keypoints.jpg',img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"UzjYp-VDLwNm","executionInfo":{"status":"error","timestamp":1641302495933,"user_tz":-540,"elapsed":332,"user":{"displayName":"백인진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16419007318722218276"}},"outputId":"e4bd0332-9fe4-494e-d201-dd203b4024be"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8b5f33635511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'home.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mkp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'SIFT_create'"]}]},{"cell_type":"code","source":["# coding: utf-8\n","import warnings\n","warnings.filterwarnings(\"ignore\")  #忽略警告\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import KNeighborsClassifier\n","from PIL import Image\n","\n","\n","\n","\n","def convolve(filter,mat,padding,strides):\n","\n","    result = None\n","    filter_size = filter.shape\n","    mat_size = mat.shape\n","    if len(filter_size) == 2:\n","        if len(mat_size) == 3: # 컬러 이미지인 경우\n","            channel = []\n","            for i in range(mat_size[-1]):\n","                pad_mat = np.pad(mat[:,:,i], ((padding[0], padding[1]), (padding[2], padding[3])), 'constant')\n","                temp = []\n","                for j in range(0,mat_size[0],strides[1]):\n","                    temp.append([])\n","                    for k in range(0,mat_size[1],strides[0]):\n","                        val = (filter*pad_mat[j:j+filter_size[0],k:k+filter_size[1]]).sum()\n","                        temp[-1].append(val)\n","                channel.append(np.array(temp))\n","\n","            channel = tuple(channel)\n","            result = np.dstack(channel)\n","        elif len(mat_size) == 2: # 흑백 이미지인 경우\n","            channel = []\n","            pad_mat = np.pad(mat, ((padding[0], padding[1]), (padding[2], padding[3])), 'constant') # 필터 적용을 위한 가장자리 패딩\n","            for j in range(0, mat_size[0], strides[1]): # stride에 따라 필터 옮겨가며 특징 추출\n","                channel.append([])\n","                for k in range(0, mat_size[1], strides[0]):\n","                    val = (filter * pad_mat[j:j + filter_size[0],k:k + filter_size[1]]).sum()\n","                    channel[-1].append(val)\n","\n","\n","            result = np.array(channel)\n","\n","\n","    return result\n","\n","\n","\n","def downsample(img,step = 2):\n","    return img[::step,::step] # 이미지 사이즈 줄이기\n","\n","def GuassianKernel(sigma , dim):\n","    '''\n","    :param sigma: Standard deviation\n","    :param dim: dimension(must be positive and also an odd number)\n","    :return: return the required Gaussian kernel.\n","    '''\n","    temp = [t - (dim//2) for t in range(dim)]\n","    assistant = []\n","    for i in range(dim):\n","        assistant.append(temp)\n","    assistant = np.array(assistant)\n","    temp = 2*sigma*sigma\n","    result = (1.0/(temp*np.pi))*np.exp(-(assistant**2+(assistant.T)**2)/temp)\n","    return result\n","\n","def getDoG(img,n,sigma0,S = None,O = None): # Difference of Gaussian 정의 함수\n","    '''\n","    :파라미터 img: 기존 이미지\n","    :파라미터 sigma0: 첫 octave 스택에 대한 시그마 default 1.52.\n","    :파라미터 n: 추출하고자 하는 피처에서 몇개의 스택을 추출할 것인가\n","    :파라미터 S: 모든 octave가 반드시 가져야 하는 stack의 최소 개수. S는 반드시 3보다 커야 함.\n","    :파라미터 k: 두개의 인접 스택의 크기 비율\n","    :파라미터 O: 몇개의 octave를 가지고 있는지\n","    '''\n","    if S == None:\n","        S = n + 3\n","    if O == None:\n","        O = int(np.log2(min(img.shape[0], img.shape[1]))) - 3\n","\n","    k = 2 ** (1.0 / n)\n","    sigma = [[(k**s)*sigma0*(1<<o) for s in range(S)] for o in range(O)]\n","    samplePyramid = [downsample(img, 1 << o) for o in range(O)]\n","\n","    GuassianPyramid = []\n","    for i in range(O):\n","        GuassianPyramid.append([])\n","        for j in range(S):\n","            dim = int(6*sigma[i][j] + 1)\n","            if dim % 2 == 0:\n","                dim += 1\n","            GuassianPyramid[-1].append(convolve(GuassianKernel(sigma[i][j], dim),samplePyramid[i],[dim//2,dim//2,dim//2,dim//2],[1,1]))\n","    DoG = [[GuassianPyramid[o][s+1] - GuassianPyramid[o][s] for s in range(S - 1)] for o in range(O)]\n","\n","\n","    return DoG,GuassianPyramid\n","\n","def adjustLocalExtrema(DoG,o,s,x,y,contrastThreshold,edgeThreshold,sigma,n,SIFT_FIXPT_SCALE): # 지역 극값을 파악하는 함수\n","    SIFT_MAX_INTERP_STEPS = 5\n","    SIFT_IMG_BORDER = 5\n","\n","    point = []\n","\n","    img_scale = 1.0 / (255 * SIFT_FIXPT_SCALE)\n","    deriv_scale = img_scale * 0.5\n","    second_deriv_scale = img_scale\n","    cross_deriv_scale = img_scale * 0.25\n","\n","    img = DoG[o][s]\n","    i = 0\n","    while i < SIFT_MAX_INTERP_STEPS:\n","        if s < 1 or s > n or y < SIFT_IMG_BORDER or y >= img.shape[1] - SIFT_IMG_BORDER or x < SIFT_IMG_BORDER or x >= img.shape[0] - SIFT_IMG_BORDER:\n","            return None,None,None,None\n","\n","        img = DoG[o][s]\n","        prev = DoG[o][s - 1]\n","        next = DoG[o][s + 1]\n","\n","        dD = [ (img[x,y + 1] - img[x, y - 1]) * deriv_scale, # 스케일 줄여가며 \n","               (img[x + 1, y] - img[x - 1, y]) * deriv_scale,\n","               (next[x, y] - prev[x, y]) * deriv_scale ]\n","\n","        v2 = img[x, y] * 2\n","        dxx = (img[x, y + 1] + img[x, y - 1] - v2) * second_deriv_scale\n","        dyy = (img[x + 1, y] + img[x - 1, y] - v2) * second_deriv_scale\n","        dss = (next[x, y] + prev[x, y] - v2) * second_deriv_scale\n","        dxy = (img[x + 1, y + 1] - img[x + 1, y - 1] - img[x - 1, y + 1] + img[x - 1, y - 1]) * cross_deriv_scale\n","        dxs = (next[x, y + 1] - next[x, y - 1] - prev[x, y + 1] + prev[x, y - 1]) * cross_deriv_scale\n","        dys = (next[x + 1, y] - next[x - 1, y] - prev[x + 1, y] + prev[x - 1, y]) * cross_deriv_scale\n","\n","        H=[ [dxx, dxy, dxs],\n","            [dxy, dyy, dys],\n","            [dxs, dys, dss]]\n","\n","        X = np.matmul(np.linalg.pinv(np.array(H)),np.array(dD))\n","\n","        xi = -X[2]\n","        xr = -X[1]\n","        xc = -X[0]\n","\n","        if np.abs(xi) < 0.5 and np.abs(xr) < 0.5 and np.abs(xc) < 0.5:\n","            break\n","\n","        y += int(np.round(xc))\n","        x += int(np.round(xr))\n","        s += int(np.round(xi))\n","\n","        i+=1\n","\n","    if i >= SIFT_MAX_INTERP_STEPS:\n","        return None,x,y,s\n","    if s < 1 or s > n or y < SIFT_IMG_BORDER or y >= img.shape[1] - SIFT_IMG_BORDER or x < SIFT_IMG_BORDER or x >= \\\n","            img.shape[0] - SIFT_IMG_BORDER:\n","        return None, None, None, None\n","\n","\n","    t = (np.array(dD)).dot(np.array([xc, xr, xi]))\n","\n","    contr = img[x,y] * img_scale + t * 0.5\n","    if np.abs( contr) * n < contrastThreshold:\n","        return None,x,y,s\n","\n","\n","    # 헤세 행렬의 궤적과 행렬식을 사용하여 주 곡률의 비율 계산.\n","    tr = dxx + dyy\n","    det = dxx * dyy - dxy * dxy\n","    if det <= 0 or tr * tr * edgeThreshold >= (edgeThreshold + 1) * (edgeThreshold + 1) * det:\n","        return None,x,y,s\n","\n","    point.append((x + xr) * (1 << o))\n","    point.append((y + xc) * (1 << o))\n","    point.append(o + (s << 8) + (int(np.round((xi + 0.5)) * 255) << 16))\n","    point.append(sigma * np.power(2.0, (s + xi) / n)*(1 << o) * 2)\n","\n","    return point,x,y,s\n","\n","def GetMainDirection(img,r,c,radius,sigma,BinNum): # keypoint의 방향 찾기\n","    expf_scale = -1.0 / (2.0 * sigma * sigma)\n","\n","    X = []\n","    Y = []\n","    W = []\n","    temphist = []\n","\n","    for i in range(BinNum):\n","        temphist.append(0.0)\n","\n","    # 이미지 기울기 히스토그램 통계의 픽셀 범위\n","    k = 0\n","    for i in range(-radius,radius+1):\n","        y = r + i\n","        if y <= 0 or y >= img.shape[0] - 1:\n","            continue\n","        for j in range(-radius,radius+1):\n","            x = c + j\n","            if x <= 0 or x >= img.shape[1] - 1:\n","                continue\n","\n","            dx = (img[y, x + 1] - img[y, x - 1])\n","            dy = (img[y - 1, x] - img[y + 1, x])\n","\n","            X.append(dx)\n","            Y.append(dy)\n","            W.append((i * i + j * j) * expf_scale)\n","            k += 1\n","\n","\n","    length = k\n","\n","    W = np.exp(np.array(W))\n","    Y = np.array(Y)\n","    X = np.array(X)\n","    Ori = np.arctan2(Y,X)*180/np.pi\n","    Mag = (X**2+Y**2)**0.5\n","\n","    # 히스토그램의 각 bin값 계산\n","    for k in range(length):\n","        bin = int(np.round((BinNum / 360.0) * Ori[k]))\n","        if bin >= BinNum:\n","            bin -= BinNum\n","        if bin < 0:\n","            bin += BinNum\n","        temphist[bin] += W[k] * Mag[k]\n","\n","    # smooth the histogram\n","    # 가우스 평활화\n","    temp = [temphist[BinNum - 1], temphist[BinNum - 2], temphist[0], temphist[1]]\n","    temphist.insert(0, temp[0])\n","    temphist.insert(0, temp[1])\n","    temphist.insert(len(temphist), temp[2])\n","    temphist.insert(len(temphist), temp[3])      # 패딩 진행\n","\n","    hist = []\n","    for i in range(BinNum):\n","        hist.append((temphist[i] + temphist[i+4]) * (1.0 / 16.0) + (temphist[i+1] + temphist[i+3]) * (4.0 / 16.0) + temphist[i+2] * (6.0 / 16.0))\n","\n","    # keypoint가 갖는 최종 방향 추출\n","    maxval = max(hist)\n","\n","    return maxval,hist\n","\n","def LocateKeyPoint(DoG,sigma,GuassianPyramid,n,BinNum = 36,contrastThreshold = 0.04,edgeThreshold = 10.0): # keypoint 위치 추출\n","    SIFT_ORI_SIG_FCTR = 1.52\n","    SIFT_ORI_RADIUS = 3 * SIFT_ORI_SIG_FCTR\n","    SIFT_ORI_PEAK_RATIO = 0.8\n","\n","    SIFT_INT_DESCR_FCTR = 512.0\n","    # SIFT_FIXPT_SCALE = 48\n","    SIFT_FIXPT_SCALE = 1\n","\n","    KeyPoints = []\n","    O = len(DoG)\n","    S = len(DoG[0])\n","    for o in range(O):\n","        for s in range(1,S-1):\n","            threshold = 0.5*contrastThreshold/(n*255*SIFT_FIXPT_SCALE) # 스케일 줄여가며\n","            img_prev = DoG[o][s-1]\n","            img = DoG[o][s]\n","            img_next = DoG[o][s+1]\n","            for i in range(img.shape[0]):\n","                for j in range(img.shape[1]):\n","                    val = img[i,j]\n","                    eight_neiborhood_prev = img_prev[max(0, i - 1):min(i + 2, img_prev.shape[0]), max(0, j - 1):min(j + 2, img_prev.shape[1])] \n","                    eight_neiborhood = img[max(0, i - 1):min(i + 2, img.shape[0]), max(0, j - 1):min(j + 2, img.shape[1])]\n","                    eight_neiborhood_next = img_next[max(0, i - 1):min(i + 2, img_next.shape[0]), max(0, j - 1):min(j + 2, img_next.shape[1])]\n","                    if np.abs(val) > threshold and \\\n","                        ((val > 0 and (val >= eight_neiborhood_prev).all() and (val >= eight_neiborhood).all() and (val >= eight_neiborhood_next).all())\n","                         or (val < 0 and (val <= eight_neiborhood_prev).all() and (val <= eight_neiborhood).all() and (val <= eight_neiborhood_next).all())):\n","\n","                        point,x,y,layer = adjustLocalExtrema(DoG,o,s,i,j,contrastThreshold,edgeThreshold,sigma,n,SIFT_FIXPT_SCALE)\n","                        if point == None:\n","                            continue\n","\n","                        scl_octv = point[-1]*0.5/(1 << o)\n","                        omax,hist = GetMainDirection(GuassianPyramid[o][layer],x,y,int(np.round(SIFT_ORI_RADIUS * scl_octv)),SIFT_ORI_SIG_FCTR * scl_octv,BinNum)\n","                        mag_thr = omax * SIFT_ORI_PEAK_RATIO\n","                        for k in range(BinNum):\n","                            if k > 0:\n","                                l = k - 1\n","                            else:\n","                                l = BinNum - 1\n","                            if k < BinNum - 1:\n","                                r2 = k + 1\n","                            else:\n","                                r2 = 0\n","                            if hist[k] > hist[l] and hist[k] > hist[r2] and hist[k] >= mag_thr:\n","                                bin = k + 0.5 * (hist[l]-hist[r2]) /(hist[l] - 2 * hist[k] + hist[r2])\n","                                if bin < 0:\n","                                    bin = BinNum + bin\n","                                else:\n","                                    if bin >= BinNum:\n","                                        bin = bin - BinNum\n","                                temp = point[:]\n","                                temp.append((360.0/BinNum) * bin)\n","                                KeyPoints.append(temp)\n","\n","\n","    return KeyPoints\n","\n","\n","def calcSIFTDescriptor(img,ptf,ori,scl,d,n,SIFT_DESCR_SCL_FCTR = 3.0,SIFT_DESCR_MAG_THR = 0.2,SIFT_INT_DESCR_FCTR = 512.0,FLT_EPSILON = 1.19209290E-07):\n","    # SIFT 서술자 계산 함수\n","    dst = []\n","    pt = [int(np.round(ptf[0])), int(np.round(ptf[1]))] # 좌표가 소수로 나올 경우 반올림\n","    cos_t = np.cos(ori * (np.pi / 180)) # 코사인\n","    sin_t = np.sin(ori * (np.pi / 180)) # 사인함수\n","    bins_per_rad = n / 360.0\n","    exp_scale = -1.0 / (d * d * 0.5)\n","    hist_width = SIFT_DESCR_SCL_FCTR * scl\n","    radius = int(np.round(hist_width * 1.4142135623730951 * (d + 1) * 0.5))\n","    cos_t /= hist_width\n","    sin_t /= hist_width\n","\n","    rows = img.shape[0]\n","    cols = img.shape[1]\n","\n","\n","    hist = [0.0]*((d+2)*(d+2)*(n+2))\n","    X = []\n","    Y = []\n","    RBin = []\n","    CBin = []\n","    W = []\n","\n","    k = 0\n","    for i in range(-radius,radius+1):\n","        for j in range(-radius,radius+1):\n","\n","            c_rot = j * cos_t - i * sin_t\n","            r_rot = j * sin_t + i * cos_t\n","            rbin = r_rot + d // 2 - 0.5\n","            cbin = c_rot + d // 2 - 0.5\n","            r = pt[1] + i\n","            c = pt[0] + j\n","\n","            if rbin > -1 and rbin < d and cbin > -1 and cbin < d and r > 0 and r < rows - 1 and c > 0 and c < cols - 1:\n","                dx = (img[r, c+1] - img[r, c-1])\n","                dy = (img[r-1, c] - img[r+1, c])\n","                X.append(dx)\n","                Y.append(dy)\n","                RBin.append(rbin)\n","                CBin.append(cbin)\n","                W.append((c_rot * c_rot + r_rot * r_rot) * exp_scale)\n","                k+=1\n","\n","    length = k\n","    Y = np.array(Y)\n","    X = np.array(X)\n","    Ori = np.arctan2(Y,X)*180/np.pi\n","    Mag = (X ** 2 + Y ** 2) ** 0.5\n","    W = np.exp(np.array(W))\n","\n","    for k in range(length):\n","        rbin = RBin[k]\n","        cbin = CBin[k]\n","        obin = (Ori[k] - ori) * bins_per_rad\n","        mag = Mag[k] * W[k]\n","\n","        r0 = int(rbin)\n","        c0 = int(cbin)\n","        o0 = int(obin)\n","        rbin -= r0\n","        cbin -= c0\n","        obin -= o0\n","\n","        if o0 < 0:\n","            o0 += n\n","        if o0 >= n:\n","            o0 -= n\n","\n","        # 삼선형 보간법을 사용한 히스토그램 업데이트\n","        v_r1 = mag * rbin\n","        v_r0 = mag - v_r1\n","\n","        v_rc11 = v_r1 * cbin\n","        v_rc10 = v_r1 - v_rc11\n","\n","        v_rc01 = v_r0 * cbin\n","        v_rc00 = v_r0 - v_rc01\n","\n","        v_rco111 = v_rc11 * obin\n","        v_rco110 = v_rc11 - v_rco111\n","\n","        v_rco101 = v_rc10 * obin\n","        v_rco100 = v_rc10 - v_rco101\n","\n","        v_rco011 = v_rc01 * obin\n","        v_rco010 = v_rc01 - v_rco011\n","\n","        v_rco001 = v_rc00 * obin\n","        v_rco000 = v_rc00 - v_rco001\n","\n","        idx = ((r0 + 1) * (d + 2) + c0 + 1) * (n + 2) + o0\n","        hist[idx] += v_rco000\n","        hist[idx+1] += v_rco001\n","        hist[idx + (n+2)] += v_rco010\n","        hist[idx + (n+3)] += v_rco011\n","        hist[idx+(d+2) * (n+2)] += v_rco100\n","        hist[idx+(d+2) * (n+2)+1] += v_rco101\n","        hist[idx+(d+3) * (n+2)] += v_rco110\n","        hist[idx+(d+3) * (n+2)+1] += v_rco111\n","\n","    # 방향 히스토그램이 원형이므로 히스토그램을 완료\n","    for i in range(d):\n","        for j in range(d):\n","            idx = ((i+1) * (d+2) + (j+1)) * (n+2)\n","            hist[idx] += hist[idx+n]\n","            hist[idx+1] += hist[idx+n+1]\n","            for k in range(n):\n","                dst.append(hist[idx+k])\n","\n","\n","    # 히스토그램을 descriptor에 복사 후\n","    # 히스테리시스 임계값 적용\n","    # 쉽게 변환할 수 있도록 결과 크기를 조정\n","    # 바이트 배열로\n","\n","    nrm2 = 0\n","    length = d * d * n\n","    for k in range(length):\n","        nrm2 += dst[k] * dst[k]\n","    thr = np.sqrt(nrm2) * SIFT_DESCR_MAG_THR\n","\n","    nrm2 = 0\n","    for i in range(length):\n","        val = min(dst[i], thr)\n","        dst[i] = val\n","        nrm2 += val * val\n","    nrm2 = SIFT_INT_DESCR_FCTR / max(np.sqrt(nrm2), FLT_EPSILON)\n","    for k in range(length):\n","        dst[k] = min(max(dst[k] * nrm2,0),255)\n","\n","    return dst\n","\n","\n","def calcDescriptors(gpyr,keypoints,SIFT_DESCR_WIDTH = 4,SIFT_DESCR_HIST_BINS = 8):\n","    # SIFT_DESCR_WIDTH = 4，히스토그램의 너비\n","    # SIFT_DESCR_HIST_BINS = 8\n","    d = SIFT_DESCR_WIDTH\n","    n = SIFT_DESCR_HIST_BINS\n","    descriptors = []\n","\n","    for i in range(len(keypoints)):\n","        kpt = keypoints[i]\n","        o = kpt[2] & 255\n","        s = (kpt[2] >> 8) & 255 # keypoint 그룹 번호 및 레이어 번호\n","        scale = 1.0 / (1 << o)  # 스케일링 범위\n","        size = kpt[3] * scale # keypoint 그룹의 이미지 크기\n","        ptf = [kpt[1] * scale, kpt[0] * scale] # 피라미드 그룹의 keypoint 좌표\n","        img = gpyr[o][s] # keypoint가 위치한 피라미드의 이미지\n","\n","        descriptors.append(calcSIFTDescriptor(img, ptf, kpt[-1], size * 0.5, d, n))\n","    return descriptors\n","\n","def SIFT(img,showDoGimgs = False):\n","    SIFT_SIGMA = 1.6\n","    SIFT_INIT_SIGMA = 0.5 \n","    sigma0 = np.sqrt(SIFT_SIGMA**2-SIFT_INIT_SIGMA**2)\n","\n","    n = 3\n","\n","    DoG,GuassianPyramid = getDoG(img, n,sigma0)\n","    if showDoGimgs:\n","        for i in DoG:\n","            for j in i:\n","                plt.imshow(j.astype(np.uint8), cmap='gray')\n","                plt.axis('off')\n","                plt.show()\n","\n","    KeyPoints = LocateKeyPoint(DoG, SIFT_SIGMA, GuassianPyramid, n)\n","    discriptors = calcDescriptors(GuassianPyramid,KeyPoints)\n","\n","    return KeyPoints,discriptors\n","\n","\n","def Lines(img,info,color = (255,0,0),err = 700):\n","\n","    if len(img.shape) == 2:\n","        result = np.dstack((img,img,img))\n","    else:\n","        result = img\n","    k = 0\n","    for i in range(result.shape[0]):\n","        for j in range(result.shape[1]):\n","            temp = (info[:,1]-info[:,0])\n","            A = (j - info[:,0])*(info[:,3]-info[:,2])\n","            B = (i - info[:,2])*(info[:,1]-info[:,0])\n","            temp[temp == 0] = 1e-9\n","            t = (j-info[:,0])/temp\n","            e = np.abs(A-B)\n","            temp = e < err\n","            if (temp*(t >= 0)*(t <= 1)).any():\n","                result[i,j] = color\n","                k+=1\n","    print(k)\n","\n","    return result\n","\n","def drawLines(X1,X2,Y1,Y2,dis,img,num = 10):\n","\n","    info = list(np.dstack((X1,X2,Y1,Y2,dis))[0])\n","    info = sorted(info,key=lambda x:x[-1])\n","    info = np.array(info)\n","    info = info[:min(num,info.shape[0]),:]\n","    img = Lines(img,info)\n","\n","    if len(img.shape) == 2:\n","        plt.imshow(img.astype(np.uint8),cmap='gray')\n","    else:\n","        plt.imshow(img.astype(np.uint8))\n","    plt.axis('off')\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    origimg = plt.imread('home.jpeg')\n","    if len(origimg.shape) ==  3:\n","        img = origimg.mean(axis=-1)\n","    else:\n","        img = origimg\n","    keyPoints,discriptors = SIFT(img)\n","\n","\n","    origimg2 = plt.imread('tmp.jpeg')\n","    if len(origimg.shape) == 3:\n","        img2 = origimg2.mean(axis=-1)\n","    else:\n","        img2 = origimg2\n","    ScaleRatio = img.shape[0]*1.0/img2.shape[0]\n","\n","    img2 = np.array(Image.fromarray(img2).resize((int(round(ScaleRatio * img2.shape[1])),img.shape[0]), Image.BICUBIC))\n","    keyPoints2, discriptors2 = SIFT(img2,True)\n","\n","    knn = KNeighborsClassifier(n_neighbors=1)\n","    knn.fit(discriptors,[0]*len(discriptors))\n","    match = knn.kneighbors(discriptors2,n_neighbors=1,return_distance=True)\n","\n","    keyPoints = np.array(keyPoints)[:,:2]\n","    keyPoints2 = np.array(keyPoints2)[:,:2]\n","\n","    keyPoints2[:, 1] = img.shape[1] + keyPoints2[:, 1]\n","\n","    origimg2 = np.array(Image.fromarray(origimg2).resize((img2.shape[1],img2.shape[0]), Image.BICUBIC))\n","    result = np.hstack((origimg,origimg2))\n","\n","\n","    keyPoints = keyPoints[match[1][:,0]]\n","\n","    X1 = keyPoints[:, 1]\n","    X2 = keyPoints2[:, 1]\n","    Y1 = keyPoints[:, 0]\n","    Y2 = keyPoints2[:, 0]\n","\n","    drawLines(X1,X2,Y1,Y2,match[0][:,0],result)\n","\n"],"metadata":{"id":"c7_LkuMaL2L9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SURF"],"metadata":{"id":"FEGbzcvkKF3b"}},{"cell_type":"code","source":["!pip uninstall opencv-contrib-python\n","!pip uninstall opencv-python\n","\n","!pip install --user opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17"],"metadata":{"id":"uLjKdNNQL1Kk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Introduction to SURF (Speeded-Up Robust Features)\n","# SIFT에 비해 속도 개선됨\n","# blurry한 이미지, 이미지 회전에 관계없이 feature 추출 가능\n","\n","img = cv.imread('home.jpg',0)\n","surf = cv.xfeatures2d.SURF_create(400)\n","kp, des = surf.detectAndCompute(img,None)\n","print(len(kp))"],"metadata":{"id":"e595U-JfL1qJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print( surf.getHessianThreshold() )\n","surf.setHessianThreshold(50000)\n","kp, des = surf.detectAndCompute(img,None)\n","print( len(kp) )"],"metadata":{"id":"UDeUGqHvL1lx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img2 = cv.drawKeypoints(img,kp,None,(255,0,0),4)\n","plt.imshow(img2),plt.show()"],"metadata":{"id":"M9_De11NL6GL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kp = surf.detect(img,None)\n","img2 = cv.drawKeypoints(img,kp,None,(255,0,0),4)\n","plt.imshow(img2),plt.show()"],"metadata":{"id":"RxpAUmN4L6De"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"MJNjFtmDL5_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### SURF scratch 코드 파일을 찾을 수 없어 다른 형식으로 사용해본 코드를 분석해보았습니다.\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","\n","data = pd.read_csv(r'.\\sign data\\data.csv')\n","\n","\n","# 각 클래스 샘플의 개수\n","\n","\n","le = [242, 259, 247, 147, 243, 226, 241, 116, 179, 245, 182, 235, 237, 229, 234, 216, 211, 229, 216, 135, 122, 128, 202, 251]\n","\n","label = []\n","for ini,folder in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']):\n","    i = ord(folder)\n","    temp = [i-65]*le[ini]\n","    label.append(temp)\n","\n","\n","\n","# 레이블을 numpy array로 변환\n","\n","label = np.concatenate(label) \n","\n","\n","# 레이블 딕셔너리 클래스 생성\n","\n","ans = {}\n","for i in range(65,90):\n","    ans[i-65] = chr(i)\n","del ans[9]\n","\n","x, y = data.values, label\n","# ind = 1090\n","# plt.imshow(x[ind].reshape(-1,128),cmap='gray')\n","# print(ans[y[ind]])\n","# plt.show()\n","\n","\n","img = cv2.GaussianBlur(x[87].reshape(-1,128).astype(np.uint8),(5,5),0)\n","edge = cv2.Canny(img,60,60)\n","plt.imshow(edge,cmap='gray')\n","plt.show()\n","\n","\n","surf = cv2.xfeatures2d.SURF_create()\n","kp = surf.detect(edge,None)\n","kp, des = surf.compute(edge, kp)\n","img2 = cv2.drawKeypoints(edge,kp,color=(0,255,0),outImage=None, flags=0)\n","plt.imshow(img2),plt.show()\n","print(des.shape[0]) \n","\n","\n","\n","\n","def pre_processing(img):\n","    # canny edge detector에는 노이즈 감소, 비최대 억제 등이 포함 -> 이러한 장점을 사용\n","    edge = cv2.Canny(img,65,65)\n","    return edge\n","\n","\n","\n","# 각 이미지를 이동하고 해당 이미지와 관련된 기능 추가\n","\n","surf = cv2.xfeatures2d.SURF_create()\n","temp = []\n","for i in range(x.shape[0]):\n","    edge = pre_processing(x[i].reshape(-1,128).astype(np.uint8))\n","    kp, des = surf.detectAndCompute(edge, None)\n","    temp.append(des)\n","\n","\n","# 모든 이미지의 모든 feature(128개 요소 벡터) 추가\n","train_desc = []\n","for desc_list in temp:\n","    for desc in desc_list:\n","        train_desc.append(desc)\n","\n","\n","train_desc = np.array(train_desc)\n","\n","\n","# k-means 클러스터링을 사용하여 기능을 클러스터링하여 시각적 단어 모델의 vbag 생성\n","\n","n_clusters = 125\n","from sklearn.cluster import MiniBatchKMeans\n","cls = MiniBatchKMeans(n_clusters)\n","\n","\n","cls.fit(train_desc)\n","\n","\n","# DBSCAN에서 찾은 클러스터 중심을 사용하여 image feature에 대한 히스토그램 제작\n","pred = []\n","for desc_list in temp:\n","    pred.append(cls.predict(desc_list))\n","\n","# 속해 있는 feature의 예측 클러스터에서 이미지에 대한 feature 벡터를 생성.\n","train_hist = [np.bincount(feature,minlength=n_clusters) for feature in pred]\n","\n","\n","train_hist = np.array(train_hist)\n","\n","\n","\n","from sklearn.svm import SVC \n","clf = SVC(kernel='linear')\n","\n"," \n","from sklearn.utils import shuffle\n","a, b = shuffle(train_hist, label, random_state=25)\n","\n","\n","# 일정 범위의 값으로 정규화\n","\n","p = a.max(axis=0)\n","a_ = []\n","for i in range(a.shape[0]):\n","    a_.append(a[i]/(p*1.0))\n","\n","a_ = np.array(a_)\n","\n","# train validation 분학\n","\n","x_train, y_train, x_test, y_test = a_[:4400], b[:4400], a_[4400:], b[4400:]\n","\n","\n","clf.fit(x_train,y_train)\n","\n","print(clf.score(x_train,y_train)*100)\n","\n","\n","\n","print(clf.score(x_test,y_test)*100)\n","\n","\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","clf1 = RandomForestClassifier(n_estimators = 50,n_jobs=-1)\n","\n","\n","\n","clf1.fit(x_train,y_train)\n","\n","print(clf1.score(x_train,y_train)*100)\n","\n","\n","print(clf1.score(x_test,y_test)*100)\n","\n","\n","\n","from sklearn.neural_network import MLPClassifier\n","clf3 = MLPClassifier()\n","\n","clf3.fit(x_train,y_train)\n","\n","\n","print(clf1.score(x_train,y_train)*100)\n","\n","\n","print(clf1.score(x_test,y_test)*100)\n","\n","\n","# SURF는 모든 기능 추출기 중에서 가장 잘 수행되는 경향이 있으므로 동일한 항목에서 혼동 행렬을 시각화 가능.\n","x = clf.predict(x_val)\n","\n","from sklearn.metrics import confusion_matrix\n","m = confusion_matrix(y_val,x)\n","\n","import seaborn as sns\n","df_cm = pd.DataFrame(m, ans.values(), ans.values())\n","plt.figure(figsize = (15,10))\n","sns.heatmap(df_cm, annot=True,fmt='g')"],"metadata":{"id":"8toSd5XpL55x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FAST"],"metadata":{"id":"n43g6WycKF1E"}},{"cell_type":"code","source":["### FAST Algorithm for Corner Detection\n","# SURF : SIFT보다 빠르나 real - time에는 어려움 있음 -> FAST 등장\n","# 실시간으로 물체의 특징을 감지하기 위해 ... 라이다(Lidar)\n","\n","img = cv.imread('chessboard2.jpg',0)\n","# Initiate FAST object with default values\n","fast = cv.FastFeatureDetector_create()\n","# find and draw the keypoints\n","kp = fast.detect(img,None)\n","img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n","# Print all default params\n","print( \"Threshold: {}\".format(fast.getThreshold()) )\n","print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n","print( \"neighborhood: {}\".format(fast.getType()) )\n","print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\n","cv.imwrite('fast_true.png', img2)\n","# Disable nonmaxSuppression\n","fast.setNonmaxSuppression(0)\n","kp = fast.detect(img, None)\n","print( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\n","img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n","\n","cv2_imshow(img3)"],"metadata":{"id":"k6VgCZ9KL-0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9tcuga7ML_nM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Performs FAST corner detection without machine generated code.\n","\n","Reference:\n","    - http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_fast/py_fast.html\n","\"\"\"\n","\n","\n","\"\"\" \n","***** Begin NumPy and OpenCV functions. ******\n","\"\"\"\n","\n","def shape(array):\n","    \"\"\" \n","    2차원 array의 shape 출력\n","    \"\"\"\n","    rows = len(array)\n","\n","    cols = len(array[0])\n","    return [rows, cols]\n","\n","def zeros(rows, cols):\n","    \"\"\"\n","    모두 0으로 채워진 2차원 array 출력\n","    \"\"\"\n","    return [[0 for col in range(cols)] for row in range(rows)]\n","\n","def rgb2gray(array):\n","    \"\"\"\n","    흑백 변환\n","    \"\"\"\n","    rows, cols = shape(array)\n","    grayscale = zeros(rows, cols)\n","    for row in range(rows):\n","        for col in range(cols):\n","            red, green, blue = array[row][col]\n","            gray = int(0.3*red + 0.59*green + 0.11*blue)\n","            grayscale[row][col] = gray\n","    return grayscale\n","\n","def medianBlur(image, startSearchRow, endSearchRow, startSearchCol, endSearchCol, N=3):\n","    \"\"\"\n","    이미지에 Median blur 효과를 수행\n","    각 픽셀을 주변 NxN 픽셀의 중앙값으로\n","    N은 홀수 정수여야 함\n","    검색 영역에 대해서만 Median blur 진행\n","    \"\"\"\n","    dst = image[:] \n","    for y in range(startSearchRow, endSearchRow):\n","        for x in range(startSearchCol, endSearchCol):\n","            window = []\n","            for i in range(y - N // 2, y + N // 2 + 1):\n","                for j in range(x - N//2, x + N//2 + 1):\n","                    window.append(image[i][j])\n","            insertionSort(window)\n","            dst[y][x] = window[len(window)//2]\n","\n","    return dst\n","    \n","def insertionSort(lst):\n","    for index in range(1, len(lst)):\n","        currentvalue = lst[index]\n","        position = index\n","\n","        while position > 0 and lst[position - 1] > currentvalue:\n","            lst[position] = lst[position - 1]\n","            position = position - 1\n","\n","        lst[position] = currentvalue\n","\n","def circle(row, col):\n","    \"\"\" \n","    픽셀 검색 영역의 둘레를 구성하는 일부 픽셀((x,y) 튜플)의 목록을 반환\n","    Circle circumference = 16 픽셀\n","\n","    \"\"\"\n","    point1 = (row+3, col)\n","    \n","    point3 = (row+3, col-1)\n","    \n","    point5 = (row+1, col+3)\n","    \n","    point7 = (row-1, col+3)\n","    \n","    point9 = (row-3, col)\n","    \n","    point11 = (row-3, col-1)\n","    \n","    point13 = (row+1, col-3)\n","    \n","    point15 = (row-1, col-3)\n","    \n","    return [point1, point3, point5, point7, point9, point11, point13, point15];\n","\n","def is_corner(image, row, col, ROI, threshold):\n","    \"\"\"\n","    circle함수에서 반환된 것과 동일한 픽셀을 사용\n","   \n","    Method:\n","        픽셀 1의 강도가 임계값 기준을 충족하는 경우 픽셀 3과 15도 임계값 기준을 충족하는지 확인 -> 조건 충족 시 corner\n","        circle 함수에서 반환된 모든 점에 대해 반복\n","        어떤 기준도 충족되지 않으면 -> corner 아님\n","        \n","        12개의 연속 픽셀 방법을 따라 여러 점을 확인\n","\n","    임계값을 높은 값으로 설정하여 더 많은 비 모서리를 걸러낼 수 있음\n","    \"\"\"\n","    intensity = int(image[row][col])\n","    row1, col1 = ROI[0]\n","    row9, col9 = ROI[4]\n","    row5, col5 = ROI[2]\n","    row13, col13 = ROI[6]\n","    intensity1 = int(image[row1][col1])\n","    intensity9 = int(image[row9][col9])\n","    intensity5 = int(image[row5][col5])\n","    intensity13 = int(image[row13][col13])\n","    count = 0\n","    if abs(intensity1 - intensity) > threshold:\n","        count += 1 \n","    if abs(intensity9 - intensity) > threshold:\n","        count += 1\n","    if abs(intensity5 - intensity) > threshold:\n","        count += 1\n","    if abs(intensity13 - intensity) > threshold:\n","        count += 1\n","\n","    return count >= 3\n","\n","def areAdjacent(point1, point2):\n","    \"\"\"\n","    행/열로 거리를 계산하여 두 점이 인접하는지 식별\n","    두 점이 서로 4픽셀 이내에 있으면 인접 (유클리디안 거리)\n","    \"\"\"\n","    row1, col1 = point1\n","    row2, col2 = point2\n","    xDist = row1 - row2\n","    yDist = col1 - col2\n","    return (xDist ** 2 + yDist ** 2) ** 0.5 <= 4\n","\n","def calculateScore(image, point, ROI):\n","    \"\"\" \n","    non-maximal suppression 점수 계산\n","    점수 V는 강도 간의 절댓값 차이의 합으로 정의\n","    circle 함수에 의해 반환된 모든 점과 중심 픽셀의 강도\n","    \"\"\"\n","    col, row = point\n","    intensity = int(image[row][col])\n","    row1, col1 = ROI[0]\n","    row3, col3 = ROI[1]\n","    row5, col5 = ROI[2]\n","    row7, col7 = ROI[3]\n","    row9, col9 = ROI[4]\n","    row11, col11 = ROI[5]\n","    row13, col13 = ROI[6]\n","    row15, col15 = ROI[7]\n","    intensity1 = int(image[row1][col1])\n","    intensity3 = int(image[row3][col3])\n","    intensity5 = int(image[row5][col5])\n","    intensity7 = int(image[row7][col7])\n","    intensity9 = int(image[row9][col9])\n","    intensity11 = int(image[row11][col11])\n","    intensity13 = int(image[row13][col13])\n","    intensity15 = int(image[row15][col15])   \n","    score = abs(intensity - intensity1) + abs(intensity - intensity3) + \\\n","            abs(intensity - intensity5) + abs(intensity - intensity7) + \\\n","            abs(intensity - intensity9) + abs(intensity - intensity11) + \\\n","            abs(intensity - intensity13) + abs(intensity - intensity15)\n","    return score\n","\n","def suppress(image, corners, ROI):\n","    \"\"\"\n","    list of corners 에서 non-maximal suppression 수행\n","    인접한 모서리의 경우 점수가 가장 작은 모서리 배제\n","    그렇지 않은경우 아무것도 하지 않음\n","\n","    이미지의 모든 픽셀을 순서대로 반복하기 때문에 인접한 corner point는 모든 list of corners에서 서로 옆에 붙어 있어야 함\n","    \"\"\"\n","    i = 1\n","    while i < len(corners):\n","        currPoint = corners[i]\n","        prevPoint = corners[i - 1]\n","        if areAdjacent(prevPoint, currPoint):\n","            currScore = calculateScore(image, currPoint, ROI)\n","            prevScore = calculateScore(image, prevPoint, ROI)\n","            if (currScore > prevScore):\n","                del(corners[i - 1])\n","            else:\n","                del(corners[i])\n","        else:\n","            i += 1\n","            continue\n","    return\n","\n","\n","\n","def detect(image, threshold=50):\n","    \"\"\"\n","    이미지에서 코너에 해당하는 픽셀을 (x,y) 튜플로 반환함\n","\n","    기본적으로 non-maximal suppression 수행\n","\n","    이미지 전체에서 코너 검색을 하는 것이 아니라 프로세스 속도를 높이기 위해 중간 부분만 검색\n","\n","    이미지는 반드시 흑백 사진이어야 함\n","    \"\"\"\n","    # Initialization\n","    image = rgb2gray(image)\n","    corners = []\n","    rows,cols = shape(image)\n","    startSearchRow = int(0.25*rows)\n","    endSearchRow = int(0.75*rows) # search the middle square of the frame\n","    startSearchCol = int(0.25*cols)\n","    endSearchCol = int(0.75*cols)\n","    image = medianBlur(image, startSearchRow, endSearchRow, startSearchCol, endSearchCol)\n","\n","    # Begin searching through search area\n","    for row in range(startSearchRow, endSearchRow):\n","        for col in range(startSearchCol, endSearchCol):\n","            ROI = circle(row, col) \n","            if is_corner(image, row, col, ROI, threshold):\n","                corners.append((col, row))\n","    suppress(image, corners, ROI) \n","    return corners;"],"metadata":{"id":"3XZTEnMZL_eI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detect('home.jpg')"],"metadata":{"id":"COVg2JxZWgm5"},"execution_count":null,"outputs":[]}]}